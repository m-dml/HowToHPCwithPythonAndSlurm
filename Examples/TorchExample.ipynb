{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is important to know, that we can not accelerate `for loops` with pytorch, but we can export vector and matrix multiplications to a GPU, which is magnitudes faster in calculating these."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "matrix_size = int(2e4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU calculation with numpy took 46.01549983024597 seconds\n"
     ]
    }
   ],
   "source": [
    "# Lets create an example test case on cpu first:\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "matrix_a = np.random.random(size=(matrix_size, matrix_size))\n",
    "matrix_b = np.random.random(size=(matrix_size, matrix_size))\n",
    "\n",
    "start_time = time.time()\n",
    "matrix_c = matrix_a @ matrix_b\n",
    "stop_time = time.time()\n",
    "\n",
    "print(f\"CPU calculation with numpy took {stop_time - start_time} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU calculation with torch took 23.7554988861084 seconds\n"
     ]
    }
   ],
   "source": [
    "# lets do the same example again on CPU but with pytorch:\n",
    "import torch\n",
    "torch.random.manual_seed(42)\n",
    "\n",
    "matrix_a = torch.randn(size=(matrix_size, matrix_size))\n",
    "matrix_b = torch.randn(size=(matrix_size, matrix_size))\n",
    "\n",
    "start_time = time.time()\n",
    "matrix_c = matrix_a @ matrix_b\n",
    "stop_time = time.time()\n",
    "\n",
    "print(f\"CPU calculation with torch took {stop_time - start_time} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is availavble: True\n"
     ]
    }
   ],
   "source": [
    "# now lets try out the same calculations on a GPU\n",
    "\n",
    "# 1. check if a GPU is available:\n",
    "print(f\"GPU is availavble: {torch.cuda.is_available()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU calculation with torch took 0.0005002021789550781 seconds\n"
     ]
    }
   ],
   "source": [
    "# when a GPU is available, we can move our arrays from the CPU-RAM to a GPU-RAM:\n",
    "\n",
    "matrix_a_gpu = matrix_a.to(\"cuda\")\n",
    "matrix_b_gpu = matrix_b.to(\"cuda\")\n",
    "\n",
    "# if we now call the computation, it will be performed on the GPU, since all matrices are on the GPU:\n",
    "with torch.no_grad():  # This line will prevent pytorch to automatically built a computational derivative for us\n",
    "    start_time = time.time()\n",
    "    matrix_c_gpu = matrix_a_gpu @ matrix_b_gpu\n",
    "    stop_time = time.time()\n",
    "\n",
    "print(f\"GPU calculation with torch took {stop_time - start_time} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# to now get back the result to a numpy array on the cpu:\n",
    "\n",
    "matrix_c_numpy = matrix_c_gpu.cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  -7.542859 ,  -58.914436 ,    1.2196629,   59.79352  ,\n        -146.47404  ],\n       [  74.833    ,  -95.34216  ,  328.45026  ,  -83.59669  ,\n          -3.9073808],\n       [-167.2056   , -172.70403  , -376.35532  ,  -76.38499  ,\n           7.7029734],\n       [ 289.7333   ,   78.743256 , -173.91449  ,  -58.590466 ,\n          48.24929  ],\n       [ 126.0523   ,  113.8273   ,  -47.19424  ,  108.30636  ,\n         -58.073307 ]], dtype=float32)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_c_numpy[:5, :5]  # lets just look at a view of the matrix, to not overload our terminal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}